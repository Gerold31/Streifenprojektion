\documentclass[ngerman,a4paper,parskip=half]{scrartcl}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[onehalfspacing]{setspace}

\usepackage{helvet}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb, amstext}
\usepackage[affil-it]{authblk}
\usepackage[round]{natbib}
\usepackage[nolist,footnote]{acronym}
\usepackage{wrapfig}
\usepackage{fancyref}
\usepackage{graphicx}
\usepackage{xcolor}

\usepackage[hidelinks]{hyperref}
%\usepackage[left=3cm,right=4cm,top=3cm,bottom=6cm,includeheadfoot]{geometry}

\def \N{\mathbb{N}}
\def \Z{\mathbb{Z}}
\def \Q{\mathbb{Q}}
\def \R{\mathbb{R}}
\def \C{\mathbb{C}}
\def \fov{\mathrm{fov}}

\begin{acronym}[FOV]
	\acro{FOV}{Field of view}
\end{acronym}

\hypersetup{
	pdftitle    = {Streifenlichtprojektion und optische Analyse zur Oberflächeninspektion},
	pdfsubject  = {Streifenlichtprojektion},
	pdfauthor   = {Dennis~Wagner, Johannes~Spangenberg, Leroy~Kramer},
	pdfkeywords = {Streifenlichtprojektion, Humboldt, HU, Informatik},
	%	pdfcreator  = {pdflatex},
	%	pdfproducer = {LaTeX with hyperref},
}

%Kopf- und Fußzeile
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}

%Kopfzeile links bzw. innen
\fancyhead[L]{\nouppercase{\leftmark}}
%Kopfzeile rechts bzw. außen
\fancyhead[R]{\today}
%Linie oben
\renewcommand{\headrulewidth}{0.5pt}

%Fußzeile mittig
\fancyfoot[C]{\thepage}
%Linie unten
\renewcommand{\footrulewidth}{0.5pt}

\begin{document}

% ---------------------------------------------------------------------------- %

\input{Streifenprojektion_Title}
\tableofcontents
\newpage

% ---------------------------------------------------------------------------- %

\section{Einleitung}

In verschiedenen Fällen ist es hilfreich oder notwendig ein \emph{komplexes} dreidimensionales Objekt zu vermessen. Aus solchen Vermessungen resultierende Modelle können in der Unterhaltungsindustrie für die Film- und Spielproduktion verwendet werden. Außerdem ermöglichen Verfahren zur Vermessung von Geometrien automatisierte Qualitätskontrollen und neue Methoden zur automatisierten Fertigung oder Verarbeitung.

In diesem Projekt wird mit der \emph{Streifenlichtprojektion} gearbeitet. Dabei wird ein Streifen auf eine Oberfläche projiziert um aus einer Aufnahme der projizierten Linie die Form der Struktur zu rekonstruieren.

% ---------------------------------------------------------------------------- %

\section{Theoretische und technische Grundlagen}

Zusätzlich zur hier verwendeten Methode haben sich in den letzten Jahrzehnten viele verschiedene Techniken entwickelt, mit denen man dreidimensionale Strukturen der realen Welt vermessen kann. So existieren zusätzlich zur Streifenlichtprojektion beispielsweise Verfahren, die \emph{Stereo-Vision}, \emph{Structure from Motion}, \emph{Shape from Shading} oder \emph{Time of Flight} verwenden. Die benötigten theoretischen Grundlagen überschneiden sich dabei bei einigen der Verfahren. Im folgenden wird auf wichtige Grundlagen des Projektes eingegangen.

\subsection{Normalisierte Bildkoordinaten}
\label{sec:imagecoordinates}

Ein Bild besteht aus einer zweidimensionalen Matrix, die für jeden Pixel eine Farbe definiert. Bei der Übertragung des Bildes auf eine Fläche unter Verwendung der Indices der Matrix als Koordinaten für die \emph{Bildpunkte} auf der Fläche stößt man schnell auf das Problem, dass die Lage des Bildpunktes erst im Zusammenhang mit der Auflösung bestimmt werden kann. Aus diesem Grund werden in verschiedenen Situationen \emph{normalisierte Bildkoordinaten} verwendet. Das Ziel der normalisierten Koordinaten ist es, die Position eines Pixels auf einer Fläche oder Ebene mit nur zwei Skalaren ausdrücken zu können.

Als normalisierte Bildkoordinaten wird hier ein Tupel aus zwei reellen Zahlen $(u,v)$ verwendet. $v$ ist dabei aus dem Intervall $[-1,1]$. Der Wertebereich von $u$ ergibt sich entsprechend aus dem Seitenverhältnis $r$: $u \in [-r,r]$. Dabei sollte erwähnt werden, dass normalisierte Bildkoordinaten oft auch so definiert werden, dass ebenfalls $u \in [-1,1]$ gilt.

Um aus den Indizes $(i,j)$ eines Pixels die normalisierten Bildkoordinaten $(u,v)$ zu berechnen, kann folgende Gleichung verwendet werden:
\[ \begin{pmatrix}
u \\ v
\end{pmatrix} = 2 \cdot \begin{pmatrix}
\frac{i r}{s_x - 1} \\
\frac{j}{s_y - 1}
\end{pmatrix} - \begin{pmatrix}
r \\ 1
\end{pmatrix} \]
Mit der Bildauflösung $(s_x, s_y)$ und dem Seitenverhältnis $r = s_x/s_y$.

\subsection{Perspektivische Projektion}

Bei einer \emph{perspektivische Projektion} werden dreidimensionale Punkte auf eine \emph{Bildebene} projiziert. Die Funktion entspricht dabei dem Modell der \emph{Lochkamera} und stellt eine Vereinfachung vieler realen Kameras da. Eine perspektivische Projektion wird durch den Augpunkt $O$ und die Bildebene definiert. Um einen Objektpunkt $X$ auf einen Punkt $X'$ in der Bildebene zu projizieren, bestimmt man den Schnittpunkt des \emph{Projektionsstrahls} durch $X$ und $O$ mit der Bildebene. Den projizierten Punkt $X'$ nennt man auch \emph{Bildpunkt}.

Oft wird die perspektivische Projektion in Verbindung mit Bildern, wie sie in \Fref{sec:imagecoordinates} definiert werden, und nicht mit konkreten Bildpunkten verwendet. Dabei ist es meistens nicht relevant, wo sich die Bildebene genau befindet, solange man jedem Pixel des Bildes genau einen Projektionsstrahl zuordnen kann. In diesem Fall wird die perspektivische Projektion meist durch den Augpunkt und eine Blickrichtung definiert. Außerdem werden Informationen zur Eingrenzung möglicher Positionen der Bildebene benötigt, um eine eindeutige Zuordnung treffen zu können.

Diese Zuordnung kann beispielsweise über die \emph{Focal length} $f$, dem Abstand zwischen Bildebene und Augpunkt, definiert werden. Angenommen die Kamera schaut in Richtung der negativen $z$-Achse, es gelte $O = (0, 0, 0)$ und $(u,v)$ seien normalisierte Bildkoordinaten des Pixels, so sieht die zugehörige Projektionsgerade G folgendermaßen aus:
\[ G = \left\lbrace \vec{w} \in \R^3 \middle\vert w = r \cdot \begin{pmatrix}
u \\ v \\ -f
\end{pmatrix} \land r \in \R^+ \right\rbrace \]

%Da die Position der Bildpunkte in einem eigenen zweidimensionalen Koordinatensystem angegeben werden, benötigten wir noch Informationen zur Position der Bildebene in der Szene. Außerdem benötigen wir Informationen zur Skalierung der Koordinaten. Die Ausrichtung der Bildebene ist bereits durch die Rotation der Kamera gegeben. Eine Möglichkeit die restlichen benötigten Informationen zu definieren ist die Angabe der \emph{Focal length} $f$ und der Ausmaße der \emph{Bildebene}. Die Focal length ist die Entfernung der Bildebene vom Augpunkt. Wir gehen davon aus, dass die Bildpunkte in einem begrenzten Wertebereich liegen und betrachten die Ausmaße des entsprechenden Wertebereiches auf der Bildebene als die Ausmaße der Bildebene. Außerdem gehen wir davon aus, dass sich der Bildpunkt $(0,0)$ in der Mitte des Wertebereichs befindet und sich der entsprechende Punkt auf der Bildebene am nächsten am Augpunkt befindet.

%Da sich die Projektion bei proportionalen Änderungen der drei Werte nicht ändert, kann die Projektion bereits durch zwei der drei Werte beschrieben werden, indem man einen der drei Werte fest definiert. Eine äquivalente Möglichkeit zur Definition der Projektion ist die Angabe des vertikalen und horizontalen \ac{FOV}.

%%Des weiteren wird die Funktion durch das vertikale und horizontale \ac{FOV} bestimmt. Statt das \ac{FOV} direkt anzugeben ist es auch möglich das \ac{FOV} indirekt durch die Angabe der \emph{Focal length} $f$ und der Ausmaße der \emph{Bildebene} $(u, v)$ zu bestimmen. Da sich das \ac{FOV} bei proportionalen Änderungen der drei Werte nicht ändert, kann das \ac{FOV} bereits durch zwei der drei Werte beschrieben werden, indem man einen der drei Werte fest definiert.

%Um aus $f$ und $v$ das vertikale \ac{FOV} zu bestimmen, kann folgende Gleichung benutzen werden:
%\[ \fov^H = 2 \cdot \arctan \left( \frac{v}{2 f} \right) \]
%Die Berechnung des horizontalen \ac{FOV} erfolgt analog mit $u$ statt $v$.

%Umgekehrt ist es auch möglich aus dem \ac{FOV} mögliche Werte für $f$, $u$ und $v$ zu bestimmen. Sei $c:(0,\Pi)^2 \to \R$ eine beliebige Funktion, so erhalten wir mit den folgenden Berechnungsvorschriften gültige Werte für $f$, $u$ und $v$:
%\begin{align*}
%f &:= c(\fov^V,\fov^H)\\
%u &:= c(\fov^V,\fov^H) \cdot 2 \tan\left(\frac{\fov^H}{2}\right)\\
%v &:= c(\fov^V,\fov^H) \cdot 2 \tan\left(\frac{\fov^V}{2}\right)
%\end{align*}

%Für ein beliebigen Objektpunkt $x = (x_1, x_2, x_3)$ und dem dazugehörigen Bildpunkt $x'$ gilt bei unseren Annahmen die folgende Gleichung:
%\[ x' = \frac{f}{2 x_3} \cdot \begin{pmatrix}
%u x_1\\v x_2
%\end{pmatrix} \]

%\[ x_1 = \frac{2 x_1' x_3}{u f} \]
%\[ x_2 = \frac{2 x_1' x_3}{v f} \]

\subsection{Triangulation}

Bei der Triangulation geht es darum, den Objektpunkt eines Bildpunktes, der bei einer bekannten Ausrichtung des Lasers vom Laser getroffen wird, zu rekonstruieren.

\subsubsection{Modell und gegebene Werte}

Das hier verwendete Modell des Setups besteht dabei im wesentlichen aus einer perspektivischen Projektion eines Objektpunktes $X$ auf eine Bildebene $B$, die parallel zur $x$-$y$-Ebene verläuft. Das Augpunkt liegt dabei im Koordinatenursprung $O$. Der Bildpunkt wird mit $X'$ bezeichnet. Das projizierte Licht wird durch eine Ebene $L$ dargestellt, die die Position des Projektors, das heißt den Projektionspunkt $P$, und den Objektpunkt $X$ schneidet.

Die durch das Setup gegebenen Werte:

\begin{tabular}{lp{12cm}}
	$P$       & Position des Linienprojektors.\\
	$f$       & Focal length (unter der Annahme, dass die Ausmaße der Bildebene zwei Einheiten nach oben betragen)\\
	$\theta$  & Winkel zur Ausrichtung des Projektors.\\
	$\delta$  & Zweiter Winkel zur Ausrichtung des Projektors.
\end{tabular}

Zudem ist der Bildpunkt durch normalisierte Bildkoordinaten $(u, v)$ gegeben. Da die Focal length $f$ auf eine Bildhöhe von zwei Einheiten angepasst ist, gilt $X'(u, v, -f)$.

\subsubsection{Bestimmung der Entfernung}

\begin{figure}
	\centering
	\includegraphics[width=6cm]{includes/triangulation2d}
	\caption{Zweidimensionales vereinfachtes Modell des Setups}
\end{figure}

Als \emph{Entfernung des Objektpunktes}, bzw. $h$, wird die 3. Koordinate von $X$ bezeichnet.

Um diese Entfernung zu bestimmen, wird das geometrische Modell des Setups vereinfacht. Als erstes wird ein Basiswechsel auf die Orthogonalbasis
\[ \left\lbrace \begin{pmatrix}
\cos(\theta) \\ \sin(\theta) \\ 0
\end{pmatrix}, \begin{pmatrix}
0 \\ 0 \\ -1
\end{pmatrix}, \begin{pmatrix}
\sin(\theta) \\ \cos(\theta) \\ 0
\end{pmatrix} \right\rbrace \]
vorgenommen, um im folgenden nur die ersten beiden Dimensionen zu betrachten. Der konstruierte zweidimensionale Raum hat die besondere Eigenschaft, dass von der Ebene $L$ und der $x$-$y$-Ebene nur die Geraden $a$ und $c$ übrig bleiben. Eine weitere besondere Eigenschaft ist, dass der Abstand zwischen $X$ und der $x$-$y$-Ebene direkt von einen in den anderen Raum übernommen werden kann. Ein beliebiger Vektor $(v_1, v_2, v_3)^T$ im dreidimensionalen Model entspricht damit im zweidimensionalen Modell dem Vektor $(\cos(\theta) \cdot v_1 - \sin(\theta) \cdot v_2, -v_3)^T$.

Die Geraden $a$ und $c$ bilden zusammen mit der Geraden $b$, welche durch die Punkte $O$, $X$ und $X'$ verläuft, ein Dreieck, dessen Eckpunkte $A$, $C = X$ und $B = O$ sind. Angenommen die Koordinaten von $P$ und $X'$ in der zweidimensionalen Darstellung sind $(p_1,p_2)$ und $(x'_1, x'_2)$, so können die Winkel $\alpha$ und $\beta$ und die Länge der Strecke zwischen $A$ und $B$ wie folgt berechnet werden:
\begin{align*}
	\alpha &= \frac{\pi}{2} - \arctan\left(\frac{x'_1}{x'_2}\right)\\
	\beta &= \frac{\pi}{2} + \delta\\
	\overline{AB} &= p_1 + \tan(\delta) \cdot p_2
\end{align*}

Die Entfernung $h$ kann daraufhin wie folgt berechnet werden:
\[ h = \frac{\overline{AB} \cdot \sin(\alpha) \cdot \sin(\beta)}{\sin(\pi - \beta - \alpha)} \]

\subsubsection{Bestimmung der Koordinaten}

Nachdem die Entfernung $h$ des Objektpunktes bekannt ist, kann der Objektpunkt $X$ recht einfach aus dem Bildpunkt bestimmt werden:
\[ \vec{x} = \frac{h}{f} \cdot \vec{x'} = \frac{h}{f} \cdot \begin{pmatrix}
u \\ v \\ -f
\end{pmatrix} \]

% ---------------------------------------------------------------------------- %

\section{Aufbau und Algorithmen}

\subsection{Hardware}

Die Hardware besteht aus einer Webcam und einem Linienlaser, der auf einem Modellbauservo montiert ist. Laser und Servo werden von einem ''Spark Core'' Mikrocontroller gesteuert, welcher wiederum über USB von der Software gesteuert wird.

\subsection{Softwarearchitektur}

Zur Implementierung der Software wurde die Programmiersprache \emph{C++} nach dem \emph{Standard von 2011} verwendet. Als Bibliotheken kamen \emph{OpenCV} und \emph{Qt} zum Einsatz.

\subsubsection{Grundlegende Datenstrukturen}

Zur Übertragung von Informationen zwischen den verschiedenen Komponenten werden die Datenstrukturen \texttt{Line}, \texttt{Reconstruction} und \texttt{DeviceConfiguration} verwendet. In \Fref{fig:classes_base} sind die entsprechenden Klassen zu sehen und in \Fref{tab:classes_base} werden ihre Funktionen beschrieben.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{includes/classdiagram_base.png}
	\caption{Klassendiagramm zu den grundlegenden Datenstrukturen}
	\label{fig:classes_base}
\end{figure}

\begin{table}
	\begin{tabular}{lp{10cm}}
		\texttt{DeviceConfiguration} &
		Die Struktur \texttt{DeviceConfiguration} speichert dabei alle Werte zum Setup, die zur Rekonstruktion benötigt werden. Zusätzlich wird eine Transformationsmatrix mitgeführt, auf die später noch eingegangen wird.\\[1em]
		\texttt{Line}                &
		Die Datenstruktur \texttt{Line} entspricht einer Menge von Abtastungen der projizierten Linie. Sie Speichert dabei zusätzlich zu einer Liste von Abtastungen (Instanzen von \texttt{Sample}) die Auflösung des zugrunde liegenden Bildes.\\[1em]
		Reconstruction               &
		Die Klasse \texttt{Reconstruction} dient zum Speichern des endgültigen Ergebnises der Rekonstruktion. Sie speichert somit eine Liste von rekonstruierten Punkten (Instanzen von \texttt{Point}). Zusätzlich hat die Klasse die Aufgabe, hinzugefügte rekonstruierte Punkte zur Ausgabe des Programms hinzuzufügen.
	\end{tabular}
	\caption{Funktion der grundlegenden Datenstrukturen}
	\label{tab:classes_base}
\end{table}

\subsubsection{Programmablauf}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{includes/classdiagram_control.png}
	\caption{Klassendiagramm zu den Steuereinheiten}
	\label{fig:classes_control}
\end{figure}

Nach Programmstart wird als erstes die Funktion \texttt{Configuration::init(int,char**)} aufgerufen. Diese analysiert die Argumente, die dem Programm übergeben wurden, und speichert das Ergebnis in den statischen Feldern der Klasse. Unter anderem wird dabei jeweils eine Instanz einer Spezialisierung der Klassen \texttt{Controller}, \texttt{LightBarDetector} und \texttt{Reconstructor} in den Feldern von \texttt{Configuration} abgelegt. Als nächstes wird die Methode \texttt{main()} des Controllers aufgerufen. Der Rest des Programmablaufes wird von der entsprechenden Methode des Controllers gesteuert.

Der Ablauf, der von den verschiedenen Spezialisierungen von \texttt{Controller} vorgegeben wird, verfolgt dabei immer einen ähnlichen Ablauf. Der Controller durchläuft eine Schleife und beschafft sich in jedem Schleifendurchlauf die aktuelle Gerätekonfiguration (\texttt{DeviceConfiguration}), eine Aufnahme durch das entsprechende Setup und ggf. ein aktuelles Referenzbild. Danach übergibt es die Steuerung an Linienerkennung (\texttt{LightBarDetextor}) und dessen Ergebnis wird an den Rekonstruktionsalgorithmus (\texttt{Reconstructor}) übergeben. Siehe zur Veranschaulichung auch {\color{red} Abbildung x}.

\subsubsection{Übersicht}

In dem Klassendiagramm auf \Fref{fig:classes_all} sind nochmal alle Klassen des Programms zu sehen.

\begin{tabular}{l|p{10cm}}
	\bfseries Klasse    & \bfseries Funktion\\
	\hline
	Configuration       &
		Diese Klasse ist eine rein statische Klasse. Sie analysiert nach Programmstart die Argumente, die an das Programm übergeben wurden, und speichert die Einstellungen für die weitere Programmausführung.\\
	\hline
	Controller          &
		Diese abstrakte Klasse bildet die Basis für alle \emph{Steuerungsklassen} und definiert Funktionen mit denen die Steuerungsklasse ihre Arbeit verrichten kann. Eine Steuerungsklasse bestimmt den Programmablauf und ist dabei für die Beschaffung der Setup-Informationen und Bilder verantwortlich.\\
	\hline
	DeviceConfiguration &
		Diese Datenstruktur speichert alle relevanten Daten zum Setup wie die Position und Ausrichtung des Projektors. Außerdem wird eine Transformationsmatrix mitgeführt, auf die später noch eingegangen wird.\\
	\hline
	LightBarDetector    &
		Diese abstrakte Klasse dient als Basis für alle Implementierungen zur Detektion der Laserlinie\\
	\hline
	Line                &
		Diese Datenstruktur repräsentiert das Zwischenergebnis der Linienerkennung. Sie speichert eine Liste der Indizes der Pixel, welche vermeintlich zur Laserlinie gehören.\\
	\hline
	Point               &
		Diese Klasse repräsentiert einen rekonstruierten Objektpunkt und ist eine Komponente der Klasse \texttt{Reconstruktion}.\\
	\hline
	Reconstruction      &
		Diese Klasse speichert das endgültige Ergebnis der Rekonstruktion. Außerdem kümmert sie sich um die Ausgabe der Objektpunkte.\\
	\hline
	Reconstructor       &
		Diese abstrakte Klasse dient als Basis für alle Implementierungen zur Rekonstruktion der Objektpunkte auf Basis der bereits erkannten Laserlinie.\\
	\hline
	Sample              &
		Ein Sample ist ein erkannter Pixel einer Laserlinie und ist folglich eine Komponente der Klasse \texttt{Line}.\\
	\hline
\end{tabular}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{includes/classdiagram}
	\caption{Umfassendes Klassendiagramm}
	\label{fig:classes_all}
\end{figure}

\subsection{Ansteuerung der Hardware}

Die Software steuert die Hardware über USB, wobei sich der Mikrocontroller als virtuellen COM-Port ausgibt. Zur Kommunikation wird ein einfaches Protokoll verwendet, das 2 Byte lange Nachrichten an den Mikrocontroller sendet. Das erste Byte gibt den Befehl an, das zweite den Parameter.\\

\begin{tabular}{|c|c|c|}
\hline
1. Byte & 2. Byte & Beschreibung \\
\hline
'm'\footnotemark & $\alpha \in [0,180]$ & Setzt die Servoposition auf $\alpha ^\circ$.\\
\hline
'l' & '0' oder '1' & Schaltet den Laser an ('1') bzw. aus ('0')\\
\hline
\end{tabular}

\footnotetext{Zeichen in Anführungszeichen stehen für den ASCII-Wert des Zeichens}


\subsection{Linienerkennung}

Es wird ein Binärbild erzeugt, wobei der Algorithmus entscheidet, welche Pixel zur Linie gehören und welche nicht. Im zweiten Schritt wird das Bild zeilenweise durchgegangen, wobei in eine seperate Datenstruktur die vermeintliche Position der Linie und deren Breite geschrieben wird. Diese Informationen werden dann an die Auswertungssoftware weitergegeben. Die hier implementierten Algorithmen unterscheiden sich lediglich in der Erzeugung des Binärbildes im ersten Schritt.

\subsubsection{Differenzbildung (Diff)}

Vor der eigentlichen Aufnahme mit dem Laser oder nach jeder einzelnen Aufnahme wird ein Bild ohne eine Linie aufgenommen. Mit jedem weiteren Bild wird die Differenz mit der Aufnahme ohne Linie gebildet und mit Hilfe einer Maske wird das Rauschen entfernt und das Bild in ein Binärbild umgewandelt.

\subsubsection{Farbfilter (Free)}

Für jeden Farbkanal wird einzeln der Mittelwert über das gesamte Bild berechnet, aus dem ein Schwellenwert für jeden Kanal einzeln bestimmt wird. Für jeden Pixel wird der Wert jedes Farbkanals mit dem Schwellenwert verglichen. Ist ein Wert keiner als der entsprechnde Schwellenwert, gehört der Pixel nicht zur Linie.

\subsection{Rekonstruktion}

Nachdem die Laserlinie erkannt wurde, werden die vermeintlichen Pixel der erkannten Linie in Objektpunkte überführt. Dies geschieht durch die Klasse \texttt{DefaultReconstructor}, welche derzeit die einzige Spezialisierung von \texttt{Reconstructor} darstellt.

Dazu werden die Formeln aus den theoretischen Grundlagen angewendet, um für jeden Pixel zunächst die normalisierten Bildkoordinaten, die Entfernung $h$ und darauf den Objektpunkt $X$ zu bestimmen. Danach werden die erhalten Punkte mithilfe der Transformationsmatrix transformiert und an die Klasse \texttt{Reconstruction} weiter gegeben.

% ---------------------------------------------------------------------------- %

\section{Auswertung}

% ---------------------------------------------------------------------------- %

\section{Zusammenfassung}

% ---------------------------------------------------------------------------- %

\section{Quellenverzeichnis}

% ---------------------------------------------------------------------------- %

\end{document}
